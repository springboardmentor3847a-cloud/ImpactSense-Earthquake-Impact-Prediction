# ===============================================================
# üìò ImpactSense - Earthquake Impact Prediction
# üß© Milestone 2: Model Development & Evaluation
# ===============================================================

# ----------------------------
# 1. Imports
# ----------------------------
import os
import warnings
warnings.filterwarnings("ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report
)

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

import joblib

# ----------------------------
# 2. Load or Create Dataset
# ----------------------------
if os.path.exists("earthquake_processed.csv"):
    print("‚úÖ Loaded dataset: earthquake_processed.csv")
    data = pd.read_csv("earthquake_processed.csv")
else:
    print("‚ö†Ô∏è 'earthquake_processed.csv' not found ‚Äî creating a sample dataset for testing.")
    from sklearn.datasets import make_classification
    X, y = make_classification(
        n_samples=500,
        n_features=6,
        n_informative=4,
        n_redundant=1,
        random_state=42
    )
    data = pd.DataFrame(X, columns=[f"feature_{i}" for i in range(6)])
    data["risk_level"] = np.random.choice(["Low", "Moderate", "High"], size=500)
    data.to_csv("earthquake_processed_sample.csv", index=False)
    print("üß© Sample dataset created as 'earthquake_processed_sample.csv'")

print("Shape:", data.shape)
print(data.head())

# ----------------------------
# 3. Prepare Features & Target
# ----------------------------
target_col = "risk_level" if "risk_level" in data.columns else data.columns[-1]
X = data.drop(columns=[target_col])
y = data[target_col]

# Encode target if needed
if y.dtype == "object" or y.dtype.name == "category":
    le = LabelEncoder()
    y = le.fit_transform(y)
    print("üî§ Target encoded:", le.classes_)

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)
print("‚úÖ Data split into training (80%) and test (20%) sets.")

# ----------------------------
# 4. Define Models
# ----------------------------
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(n_estimators=100, random_state=42)
}

# ----------------------------
# 5. Train & Evaluate Models
# ----------------------------
results = []

for name, model in models.items():
    print(f"\nüöÄ Training {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, average="weighted", zero_division=0)
    rec = recall_score(y_test, y_pred, average="weighted", zero_division=0)
    f1 = f1_score(y_test, y_pred, average="weighted", zero_division=0)

    results.append({
        "Model": name,
        "Accuracy": acc,
        "Precision": prec,
        "Recall": rec,
        "F1_Score": f1
    })

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(5,4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
    plt.title(f"Confusion Matrix - {name}")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.show()

# ----------------------------
# 6. Model Comparison
# ----------------------------
results_df = pd.DataFrame(results).sort_values(by="Accuracy", ascending=False)
print("\nüìä Model Performance Comparison:")
print(results_df)

plt.figure(figsize=(8,5))
sns.barplot(x="Model", y="Accuracy", data=results_df, palette="viridis")
plt.title("Model Accuracy Comparison")
plt.xticks(rotation=15)
plt.show()

# ----------------------------
# 7. Save Best Model
# ----------------------------
best_model_name = results_df.iloc[0]["Model"]
best_model = models[best_model_name]

joblib.dump(best_model, "Best_Earthquake_Model.pkl")
print(f"\nüíæ Best model saved as 'Best_Earthquake_Model.pkl' ({best_model_name})")

# ----------------------------
# 8. Feature Importance (for Tree Models)
# ----------------------------
if hasattr(best_model, "feature_importances_"):
    feat_imp = pd.DataFrame({
        "Feature": X.columns,
        "Importance": best_model.feature_importances_
    }).sort_values(by="Importance", ascending=False)

    plt.figure(figsize=(8,5))
    sns.barplot(x="Importance", y="Feature", data=feat_imp, palette="magma")
    plt.title(f"Top Features - {best_model_name}")
    plt.show()
else:
    print(f"‚ö†Ô∏è {best_model_name} does not support feature importance display.")

# ----------------------------
# 9. Save Evaluation Report
# ----------------------------
results_df.to_csv("Milestone2_Model_Results.csv", index=False)
print("‚úÖ Results saved to 'Milestone2_Model_Results.csv'")

# ----------------------------
# 10. Next Steps (Milestone 3)
# ----------------------------
print("\nüöÄ Next Steps for Milestone 3:")
print("1Ô∏è‚É£ Evaluate the best model using cross-validation and learning curves.")
print("2Ô∏è‚É£ Generate feature importance and SHAP explainability plots.")
print("3Ô∏è‚É£ Create an evaluation report summarizing model performance.")
